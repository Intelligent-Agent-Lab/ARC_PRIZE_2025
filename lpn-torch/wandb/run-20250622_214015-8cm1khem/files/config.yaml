wandb_version: 1

training:
  desc: null
  value:
    seed: 0
    resume_from_checkpoint: null
    inference_mode: mean
    inference_kwargs: null
    batch_size: 128
    gradient_accumulation_steps: 1
    total_num_steps: 200000
    log_every_n_steps: 1000
    eval_every_n_logs: 20
    save_checkpoint_every_n_logs: 200
    learning_rate: 0.0004
    prior_kl_coeff: 0.001
    pairwise_kl_coeff: null
    mixed_precision: false
    online_data_augmentation: false
    task_generator:
      num_workers: 16
      num_pairs: 4
      class: PATTERN
      pattern_size: 2
      num_rows: 4
      num_cols: 4
    train_datasets: null
    use_hf: true
eval:
  desc: null
  value:
    eval_datasets: null
    test_datasets:
    - generator: PATTERN
      task_generator_kwargs:
        pattern_size: 2
        num_rows: 4
        num_cols: 4
      name: generator_mean
      num_pairs: 4
      length: 96
      batch_size: 96
      num_tasks_to_show: 32
    - generator: PATTERN
      task_generator_kwargs:
        pattern_size: 2
        num_rows: 4
        num_cols: 4
      name: generator_gradient_ascent_5
      num_pairs: 4
      length: 96
      batch_size: 96
      num_tasks_to_show: 32
      inference_mode: gradient_ascent
      inference_kwargs:
        num_steps: 10
        lr: 0.1
    json_datasets: null
encoder_transformer:
  desc: null
  value:
    _target_: src.models.utils.EncoderTransformerConfig
    max_rows: 4
    max_cols: 4
    num_layers: 2
    transformer_layer:
      _target_: src.models.utils.TransformerLayerConfig
      num_heads: 6
      emb_dim_per_head: 12
      mlp_dim_factor: 4.0
      dropout_rate: 0.0
      attention_dropout_rate: 0.0
    latent_dim: 2
    variational: true
    latent_projection_bias: false
decoder_transformer:
  desc: null
  value:
    _target_: src.models.utils.DecoderTransformerConfig
    max_rows: 4
    max_cols: 4
    num_layers: 2
    transformer_layer:
      _target_: src.models.utils.TransformerLayerConfig
      num_heads: 6
      emb_dim_per_head: 12
      mlp_dim_factor: 4.0
      dropout_rate: 0.0
      attention_dropout_rate: 0.0
_wandb:
  desc: null
  value:
    code_path: code/src/train.py
    python_version: 3.10.18
    cli_version: 0.17.3
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1750596015
    t:
      1:
      - 1
      - 5
      - 12
      - 49
      - 50
      - 53
      - 55
      3:
      - 16
      - 23
      4: 3.10.18
      5: 0.17.3
      8:
      - 5
      13: darwin-arm64
